train_file:/home/syp/zwr/txtgen/examples/long_text/yahoo_data/yahoo.train.txt
valid_file:/home/syp/zwr/txtgen/examples/long_text/yahoo_data/yahoo.valid.txt
logdir:./log_dir/bsize64.epoch70.lr_c2warm16000.baseline/
epoch:0 eval_bleu:0.04707319021690637
the 0 epoch, highest bleu 0.047073
epoch:1 eval_bleu:0.7857516407966614
the 1 epoch, highest bleu 0.785752
epoch:2 eval_bleu:0.72240075096488
step:500 source:(64, 66) loss:6.72627
epoch:3 eval_bleu:0.775246974080801
epoch:4 eval_bleu:0.783579982817173
epoch:5 eval_bleu:0.7960649207234383
the 5 epoch, highest bleu 0.796065
step:1000 source:(64, 66) loss:6.85487
epoch:6 eval_bleu:0.8737671189010143
the 6 epoch, highest bleu 0.873767
epoch:7 eval_bleu:0.7716014049947262
epoch:8 eval_bleu:0.7287591230124235
step:1500 source:(64, 66) loss:6.62456
epoch:9 eval_bleu:0.9827072732150555
the 9 epoch, highest bleu 0.982707
epoch:10 eval_bleu:0.9916124865412712
the 10 epoch, highest bleu 0.991612
epoch:11 eval_bleu:1.0625161230564117
the 11 epoch, highest bleu 1.062516
step:2000 source:(64, 66) loss:6.33869
epoch:12 eval_bleu:1.1326026171445847
the 12 epoch, highest bleu 1.132603
epoch:13 eval_bleu:1.232988853007555
the 13 epoch, highest bleu 1.232989
epoch:14 eval_bleu:1.4609843492507935
the 14 epoch, highest bleu 1.460984
step:2500 source:(64, 66) loss:6.1394
epoch:15 eval_bleu:1.26804169267416
epoch:16 eval_bleu:1.337348110973835
epoch:17 eval_bleu:1.3202935457229614
epoch:18 eval_bleu:1.292958203703165
step:3000 source:(64, 66) loss:6.05652
epoch:19 eval_bleu:1.402236893773079
epoch:20 eval_bleu:1.17079121991992
epoch:21 eval_bleu:1.4125210233032703
step:3500 source:(64, 66) loss:5.95994
epoch:22 eval_bleu:1.3419807888567448
epoch:23 eval_bleu:1.2950995936989784
epoch:24 eval_bleu:1.368916779756546
step:4000 source:(64, 66) loss:5.60372
epoch:25 eval_bleu:1.5991393476724625
the 25 epoch, highest bleu 1.599139
epoch:26 eval_bleu:1.4694290235638618
epoch:27 eval_bleu:1.3195255771279335
step:4500 source:(64, 66) loss:5.66393
epoch:28 eval_bleu:1.6043288633227348
the 28 epoch, highest bleu 1.604329
epoch:29 eval_bleu:1.2878579087555408
epoch:30 eval_bleu:1.2889250181615353
step:5000 source:(64, 66) loss:5.36062
epoch:31 eval_bleu:1.316482201218605
epoch:32 eval_bleu:1.3280072249472141
epoch:33 eval_bleu:1.2150336056947708
epoch:34 eval_bleu:1.2308195233345032
step:5500 source:(64, 66) loss:5.27005
epoch:35 eval_bleu:1.031456794589758
epoch:36 eval_bleu:1.2215465307235718
epoch:37 eval_bleu:1.1579755693674088
step:6000 source:(64, 66) loss:4.95787
epoch:38 eval_bleu:1.1108970269560814
epoch:39 eval_bleu:1.3354934751987457
epoch:40 eval_bleu:1.2476659379899502
step:6500 source:(64, 66) loss:4.80867
epoch:41 eval_bleu:1.2841817922890186
epoch:42 eval_bleu:1.248257141560316
epoch:43 eval_bleu:1.3421133160591125
step:7000 source:(64, 66) loss:4.59766
epoch:44 eval_bleu:1.3417813926935196
epoch:45 eval_bleu:1.3146976940333843
epoch:46 eval_bleu:1.339471247047186
step:7500 source:(64, 66) loss:4.36828
epoch:47 eval_bleu:1.3006615452468395
epoch:48 eval_bleu:1.137211173772812
epoch:49 eval_bleu:1.1985445395112038
step:8000 source:(64, 66) loss:4.36911
epoch:50 eval_bleu:1.1277338489890099
epoch:51 eval_bleu:1.2331744655966759
epoch:52 eval_bleu:1.4501367695629597
epoch:53 eval_bleu:1.278998889029026
step:8500 source:(64, 66) loss:3.994
epoch:54 eval_bleu:1.4722490683197975
epoch:55 eval_bleu:1.3372634537518024
epoch:56 eval_bleu:1.3408969156444073
step:9000 source:(64, 66) loss:3.79068
epoch:57 eval_bleu:1.2141176499426365
epoch:58 eval_bleu:1.3960018754005432
epoch:59 eval_bleu:1.3170257210731506
step:9500 source:(64, 66) loss:3.51839
epoch:60 eval_bleu:1.2107033282518387
epoch:61 eval_bleu:1.282973401248455
epoch:62 eval_bleu:1.4343593269586563
step:10000 source:(64, 66) loss:3.36425
epoch:63 eval_bleu:1.3374044559895992
epoch:64 eval_bleu:1.4133235439658165
epoch:65 eval_bleu:1.4680521562695503
step:10500 source:(64, 66) loss:3.16356
epoch:66 eval_bleu:1.2642966583371162
epoch:67 eval_bleu:1.4063620008528233
epoch:68 eval_bleu:1.134539395570755
epoch:69 eval_bleu:1.2822211720049381
/home/syp/miniconda2/envs/newtf/lib/python3.6/importlib/_bootstrap.py:205: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6
  return f(*args, **kwds)
/home/syp/miniconda2/envs/newtf/lib/python3.6/site-packages/matplotlib/pyplot.py:537: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  max_open_warning, RuntimeWarning)
