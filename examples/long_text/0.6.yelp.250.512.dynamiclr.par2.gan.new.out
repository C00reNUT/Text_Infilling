train_file:/home/syp/zwr/txtgen/examples/long_text/yelp_data/pos/pos.train.txt
valid_file:/home/syp/zwr/txtgen/examples/long_text/yelp_data/pos/pos.valid.txt
logdir:./log_dir/pos.bsize250.epoch150.seqlen16.dynamic_lr.fixed_mask.present0.6.partition2.hidden512.gan/
step:33401 source:(250, 17) g_loss:1.559684 d_loss:0.000000 ppl:4.744217 lr:0.000242
step:33601 source:(250, 17) g_loss:1.542443 d_loss:0.000000 ppl:4.662971 lr:0.000241
step:33801 source:(250, 17) g_loss:1.574657 d_loss:0.000000 ppl:4.815094 lr:0.000240
step:34001 source:(250, 17) g_loss:1.564921 d_loss:0.000000 ppl:4.768654 lr:0.000240
step:34201 source:(250, 17) g_loss:1.602528 d_loss:0.000000 ppl:4.951150 lr:0.000239
step:34401 source:(250, 17) g_loss:1.561305 d_loss:0.000000 ppl:4.751001 lr:0.000238
step:34601 source:(250, 17) g_loss:1.551343 d_loss:0.000000 ppl:4.704056 lr:0.000238
step:34801 source:(250, 17) g_loss:1.553272 d_loss:0.000000 ppl:4.713269 lr:0.000237
step:35001 source:(250, 17) g_loss:1.520344 d_loss:0.000000 ppl:4.560683 lr:0.000236
epoch:125 test_bleu:55.420440435409546 template_bleu:38.278621435165405 test_loss:3.945925712585449 test_ppl:91.28235626220703 
epoch:125 train_g_bleu:94.07399296760559 template_bleu:37.78722882270813 train_g_loss:1.5239386558532715 train_g_ppl:4.61153507232666 
step:35201 source:(250, 17) g_loss:1.516096 d_loss:0.000000 ppl:4.541181 lr:0.000236
step:35401 source:(250, 17) g_loss:1.540540 d_loss:0.000000 ppl:4.653816 lr:0.000235
step:35601 source:(250, 17) g_loss:1.495307 d_loss:0.000000 ppl:4.447869 lr:0.000234
step:35801 source:(250, 17) g_loss:1.510601 d_loss:0.000000 ppl:4.516692 lr:0.000234
step:36001 source:(250, 17) g_loss:1.514494 d_loss:0.000000 ppl:4.534194 lr:0.000233
step:36201 source:(250, 17) g_loss:1.492944 d_loss:0.000000 ppl:4.437470 lr:0.000232
step:36401 source:(250, 17) g_loss:1.502883 d_loss:0.000000 ppl:4.481976 lr:0.000232
step:36601 source:(250, 17) g_loss:1.516687 d_loss:0.000000 ppl:4.544329 lr:0.000231
step:36801 source:(250, 17) g_loss:1.488550 d_loss:0.000000 ppl:4.418117 lr:0.000230
step:37001 source:(250, 17) g_loss:1.506315 d_loss:0.000000 ppl:4.497335 lr:0.000230
epoch:130 test_bleu:55.194246768951416 template_bleu:38.278621435165405 test_loss:3.90920352935791 test_ppl:74.25850677490234 
epoch:130 train_g_bleu:95.7224190235138 template_bleu:37.78722882270813 train_g_loss:1.4806938171386719 train_g_ppl:4.4083943367004395 
step:37201 source:(250, 17) g_loss:1.509537 d_loss:0.000000 ppl:4.511879 lr:0.000229
step:37401 source:(250, 17) g_loss:1.502420 d_loss:0.000000 ppl:4.479804 lr:0.000229
step:37601 source:(250, 17) g_loss:1.503928 d_loss:0.000000 ppl:4.486559 lr:0.000228
step:37801 source:(250, 17) g_loss:1.491947 d_loss:0.000000 ppl:4.433016 lr:0.000227
step:38001 source:(250, 17) g_loss:1.493441 d_loss:0.000000 ppl:4.439795 lr:0.000227
step:38201 source:(250, 17) g_loss:1.494921 d_loss:0.000000 ppl:4.446208 lr:0.000226
step:38401 source:(250, 17) g_loss:1.487812 d_loss:0.000000 ppl:4.414748 lr:0.000226
step:38601 source:(250, 17) g_loss:1.493444 d_loss:0.000000 ppl:4.439651 lr:0.000225
step:38801 source:(250, 17) g_loss:1.481276 d_loss:0.000000 ppl:4.385992 lr:0.000224
step:39001 source:(250, 17) g_loss:1.517557 d_loss:0.000000 ppl:4.548022 lr:0.000224
epoch:135 test_bleu:55.39852976799011 template_bleu:38.278621435165405 test_loss:3.942775011062622 test_ppl:84.02769470214844 
epoch:135 train_g_bleu:93.65829825401306 template_bleu:37.78722882270813 train_g_loss:1.5224775075912476 train_g_ppl:4.621406555175781 
step:39201 source:(250, 17) g_loss:1.490662 d_loss:0.000000 ppl:4.427538 lr:0.000223
step:39401 source:(250, 17) g_loss:1.493387 d_loss:0.000000 ppl:4.439529 lr:0.000223
step:39601 source:(250, 17) g_loss:1.475896 d_loss:0.000000 ppl:4.362800 lr:0.000222
step:39801 source:(250, 17) g_loss:1.492419 d_loss:0.000000 ppl:4.435294 lr:0.000222
step:40001 source:(250, 17) g_loss:1.500113 d_loss:0.000000 ppl:4.469399 lr:0.000221
step:40201 source:(250, 17) g_loss:1.490221 d_loss:0.000000 ppl:4.425404 lr:0.000220
step:40401 source:(250, 17) g_loss:1.489531 d_loss:0.000000 ppl:4.422766 lr:0.000220
step:40601 source:(250, 17) g_loss:1.466883 d_loss:0.000000 ppl:4.323574 lr:0.000219
step:40801 source:(250, 17) g_loss:1.477391 d_loss:0.000000 ppl:4.369344 lr:0.000219
step:41001 source:(250, 17) g_loss:1.471389 d_loss:0.000000 ppl:4.342805 lr:0.000218
step:41201 source:(250, 17) g_loss:1.488881 d_loss:0.000000 ppl:4.419534 lr:0.000218
epoch:140 test_bleu:55.49038648605347 template_bleu:38.278621435165405 test_loss:3.9374938011169434 test_ppl:72.12569427490234 
epoch:140 train_g_bleu:94.95589137077332 template_bleu:37.78722882270813 train_g_loss:1.4875644445419312 train_g_ppl:4.452949047088623 
step:41401 source:(250, 17) g_loss:1.470034 d_loss:0.000000 ppl:4.336848 lr:0.000217
step:41601 source:(250, 17) g_loss:1.469327 d_loss:0.000000 ppl:4.334231 lr:0.000217
step:41801 source:(250, 17) g_loss:1.481758 d_loss:0.000000 ppl:4.387790 lr:0.000216
step:42001 source:(250, 17) g_loss:1.471254 d_loss:0.000000 ppl:4.342154 lr:0.000216
step:42201 source:(250, 17) g_loss:1.466180 d_loss:0.000000 ppl:4.320355 lr:0.000215
step:42401 source:(250, 17) g_loss:1.471782 d_loss:0.000000 ppl:4.344584 lr:0.000215
step:42601 source:(250, 17) g_loss:1.466676 d_loss:0.000000 ppl:4.322161 lr:0.000214
step:42801 source:(250, 17) g_loss:1.473044 d_loss:0.000000 ppl:4.350119 lr:0.000214
step:43001 source:(250, 17) g_loss:1.463542 d_loss:0.000000 ppl:4.309168 lr:0.000213
step:43201 source:(250, 17) g_loss:1.465588 d_loss:0.000000 ppl:4.317548 lr:0.000213
epoch:145 test_bleu:54.751431941986084 template_bleu:38.278621435165405 test_loss:3.9903006553649902 test_ppl:74.64008331298828 
epoch:145 train_g_bleu:97.59971499443054 template_bleu:37.78722882270813 train_g_loss:1.4349274635314941 train_g_ppl:4.207480430603027 
step:43401 source:(250, 17) g_loss:1.467325 d_loss:0.000000 ppl:4.325232 lr:0.000212
step:43601 source:(250, 17) g_loss:1.478442 d_loss:0.000000 ppl:4.373446 lr:0.000212
step:43801 source:(250, 17) g_loss:1.474421 d_loss:0.000000 ppl:4.356277 lr:0.000211
step:44001 source:(250, 17) g_loss:1.467943 d_loss:0.000000 ppl:4.327763 lr:0.000211
step:44201 source:(250, 17) g_loss:1.467831 d_loss:0.000000 ppl:4.327116 lr:0.000210
step:44401 source:(250, 17) g_loss:1.460208 d_loss:0.000000 ppl:4.294605 lr:0.000210
step:44601 source:(250, 17) g_loss:1.475301 d_loss:0.000000 ppl:4.360077 lr:0.000209
step:44801 source:(250, 17) g_loss:1.466426 d_loss:0.000000 ppl:4.321571 lr:0.000209
step:45001 source:(250, 17) g_loss:1.491313 d_loss:0.000000 ppl:4.430133 lr:0.000208
epoch:149 test_bleu:55.32633662223816 template_bleu:38.278621435165405 test_loss:3.9137609004974365 test_ppl:70.1955337524414 
epoch:149 train_g_bleu:95.74973583221436 template_bleu:37.78722882270813 train_g_loss:1.4678237438201904 train_g_ppl:4.358087062835693 
step:45201 source:(250, 17) g_loss:1.474224 d_loss:0.000000 ppl:4.354743 lr:0.000208
step:45401 source:(250, 17) g_loss:1.462336 d_loss:0.000000 ppl:4.303623 lr:0.000207
/home/syp/miniconda2/envs/newtf/lib/python3.6/importlib/_bootstrap.py:205: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6
  return f(*args, **kwds)
