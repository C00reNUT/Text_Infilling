epoch   0, step: 1: train_ppl: 81.639235
epoch 0 BLEU1~4 on train dataset:
0.794352
0.295318
0.063297
0.008683

 epoch 0 BLEU1~4 on test dataset:
0.591133
0.188237
0.031989
0.003123


epoch   1, step: 1: train_ppl: 9.845531
epoch   2, step: 1: train_ppl: 7.581516
epoch   3, step: 1: train_ppl: 6.825316
epoch   4, step: 1: train_ppl: 6.315985
epoch   5, step: 1: train_ppl: 6.025601
epoch   6, step: 1: train_ppl: 5.782121
epoch   7, step: 1: train_ppl: 5.577485
epoch   8, step: 1: train_ppl: 5.392904
epoch   9, step: 1: train_ppl: 5.227966
epoch  10, step: 1: train_ppl: 5.115403
epoch 10 BLEU1~4 on train dataset:
0.803774
0.537933
0.262999
0.099496

 epoch 10 BLEU1~4 on test dataset:
0.584465
0.282991
0.110038
0.035323


epoch  11, step: 1: train_ppl: 4.998987
epoch  12, step: 1: train_ppl: 4.910588
epoch  13, step: 1: train_ppl: 4.827782
epoch  14, step: 1: train_ppl: 4.756931
epoch  15, step: 1: train_ppl: 4.698440
epoch  16, step: 1: train_ppl: 4.648727
epoch  17, step: 1: train_ppl: 4.586263
epoch  18, step: 1: train_ppl: 4.535288
epoch  19, step: 1: train_ppl: 4.500533
epoch  20, step: 1: train_ppl: 4.441279
epoch 20 BLEU1~4 on train dataset:
0.818169
0.564567
0.294734
0.120116

 epoch 20 BLEU1~4 on test dataset:
0.597310
0.290221
0.116669
0.039177


epoch  21, step: 1: train_ppl: 4.404166
epoch  22, step: 1: train_ppl: 4.407428
epoch  23, step: 1: train_ppl: 4.370182
epoch  24, step: 1: train_ppl: 4.344923
epoch  25, step: 1: train_ppl: 4.306229
epoch  26, step: 1: train_ppl: 4.267198
epoch  27, step: 1: train_ppl: 4.249881
epoch  28, step: 1: train_ppl: 4.218323
epoch  29, step: 1: train_ppl: 4.183507
epoch  30, step: 1: train_ppl: 4.148823
epoch 30 BLEU1~4 on train dataset:
0.820900
0.574503
0.303851
0.126414

 epoch 30 BLEU1~4 on test dataset:
0.603490
0.296167
0.119854
0.040613


epoch  31, step: 1: train_ppl: 4.136534
epoch  32, step: 1: train_ppl: 4.127478
epoch  33, step: 1: train_ppl: 4.129617
epoch  34, step: 1: train_ppl: 4.090453
epoch  35, step: 1: train_ppl: 4.081553
epoch  36, step: 1: train_ppl: 4.085494
epoch  37, step: 1: train_ppl: 4.076167
epoch  38, step: 1: train_ppl: 4.052643
epoch  39, step: 1: train_ppl: 4.059683
epoch  40, step: 1: train_ppl: 4.051196
epoch 40 BLEU1~4 on train dataset:
0.805618
0.565129
0.301612
0.126787

 epoch 40 BLEU1~4 on test dataset:
0.607567
0.296108
0.120413
0.041592


epoch  41, step: 1: train_ppl: 4.064166
epoch  42, step: 1: train_ppl: 4.060589
epoch  43, step: 1: train_ppl: 4.063842
epoch  44, step: 1: train_ppl: 4.038250
epoch  45, step: 1: train_ppl: 3.972226
epoch  46, step: 1: train_ppl: 3.955907
epoch  47, step: 1: train_ppl: 3.981401
epoch  48, step: 1: train_ppl: 3.948641
epoch  49, step: 1: train_ppl: 3.953702
epoch  50, step: 1: train_ppl: 3.914702
epoch 50 BLEU1~4 on train dataset:
0.827611
0.577848
0.311307
0.135343

 epoch 50 BLEU1~4 on test dataset:
0.611003
0.298571
0.120855
0.042532


epoch  51, step: 1: train_ppl: 3.910314
epoch  52, step: 1: train_ppl: 3.918085
epoch  53, step: 1: train_ppl: 3.906543
epoch  54, step: 1: train_ppl: 3.895395
epoch  55, step: 1: train_ppl: 3.878320
epoch  56, step: 1: train_ppl: 3.904138
epoch  57, step: 1: train_ppl: 3.872810
epoch  58, step: 1: train_ppl: 3.880000
epoch  59, step: 1: train_ppl: 3.861995
epoch  60, step: 1: train_ppl: 3.853741
epoch 60 BLEU1~4 on train dataset:
0.822051
0.578518
0.316262
0.138506

 epoch 60 BLEU1~4 on test dataset:
0.602807
0.295930
0.120332
0.041956


epoch  61, step: 1: train_ppl: 3.845277
epoch  62, step: 1: train_ppl: 3.828631
epoch  63, step: 1: train_ppl: 3.827409
epoch  64, step: 1: train_ppl: 3.821004
epoch  65, step: 1: train_ppl: 3.789979
epoch  66, step: 1: train_ppl: 3.801008
epoch  67, step: 1: train_ppl: 3.827816
epoch  68, step: 1: train_ppl: 3.772732
epoch  69, step: 1: train_ppl: 3.781868
epoch  70, step: 1: train_ppl: 3.800731
epoch 70 BLEU1~4 on train dataset:
0.827560
0.581789
0.316364
0.137956

 epoch 70 BLEU1~4 on test dataset:
0.605093
0.298918
0.120601
0.041251


epoch  71, step: 1: train_ppl: 3.794044
epoch  72, step: 1: train_ppl: 3.793085
epoch  73, step: 1: train_ppl: 3.789708
epoch  74, step: 1: train_ppl: 3.780872
epoch  75, step: 1: train_ppl: 3.765696
epoch  76, step: 1: train_ppl: 3.757131
epoch  77, step: 1: train_ppl: 3.733728
epoch  78, step: 1: train_ppl: 3.753437
epoch  79, step: 1: train_ppl: 3.711618
d pretrain epoch  0, step 0: dis_total_loss: 16.657263, r_loss: 8.789272, f_loss: 7.867990
d pretrain epoch  1, step 0: dis_total_loss: 3.317280, r_loss: 1.379951, f_loss: 1.937329
d pretrain epoch  2, step 0: dis_total_loss: 1.798969, r_loss: 0.681685, f_loss: 1.117284
d pretrain epoch  3, step 0: dis_total_loss: 1.187584, r_loss: 0.432838, f_loss: 0.754745
d pretrain epoch  4, step 0: dis_total_loss: 0.804107, r_loss: 0.287230, f_loss: 0.516877
d pretrain epoch  5, step 0: dis_total_loss: 0.635743, r_loss: 0.201313, f_loss: 0.434431
d pretrain epoch  6, step 0: dis_total_loss: 0.479976, r_loss: 0.135775, f_loss: 0.344202
d pretrain epoch  7, step 0: dis_total_loss: 0.322528, r_loss: 0.095662, f_loss: 0.226866
d pretrain epoch  8, step 0: dis_total_loss: 0.318579, r_loss: 0.080457, f_loss: 0.238121
d pretrain epoch  9, step 0: dis_total_loss: 0.254738, r_loss: 0.059766, f_loss: 0.194972
d pretrain epoch 10, step 0: dis_total_loss: 0.280457, r_loss: 0.045820, f_loss: 0.234637
d pretrain epoch 11, step 0: dis_total_loss: 0.261768, r_loss: 0.035339, f_loss: 0.226429
d pretrain epoch 12, step 0: dis_total_loss: 0.192861, r_loss: 0.028665, f_loss: 0.164196
d pretrain epoch 13, step 0: dis_total_loss: 0.149022, r_loss: 0.023645, f_loss: 0.125377
d pretrain epoch 14, step 0: dis_total_loss: 0.134051, r_loss: 0.018819, f_loss: 0.115231
d pretrain epoch 15, step 0: dis_total_loss: 0.132918, r_loss: 0.015170, f_loss: 0.117748
d pretrain epoch 16, step 0: dis_total_loss: 0.118039, r_loss: 0.012376, f_loss: 0.105663
d pretrain epoch 17, step 0: dis_total_loss: 0.092492, r_loss: 0.010363, f_loss: 0.082129
d pretrain epoch 18, step 0: dis_total_loss: 0.101246, r_loss: 0.008567, f_loss: 0.092679
d pretrain epoch 19, step 0: dis_total_loss: 0.073933, r_loss: 0.007120, f_loss: 0.066813
d pretrain epoch 20, step 0: dis_total_loss: 0.078804, r_loss: 0.005975, f_loss: 0.072829
d pretrain epoch 21, step 0: dis_total_loss: 0.048623, r_loss: 0.005045, f_loss: 0.043578
d pretrain epoch 22, step 0: dis_total_loss: 0.068274, r_loss: 0.004284, f_loss: 0.063991
d pretrain epoch 23, step 0: dis_total_loss: 0.046477, r_loss: 0.004294, f_loss: 0.042182
d pretrain epoch 24, step 0: dis_total_loss: 0.054848, r_loss: 0.003656, f_loss: 0.051192
d pretrain epoch 25, step 0: dis_total_loss: 0.061740, r_loss: 0.002984, f_loss: 0.058756
d pretrain epoch 26, step 0: dis_total_loss: 0.037492, r_loss: 0.002539, f_loss: 0.034953
d pretrain epoch 27, step 0: dis_total_loss: 0.061928, r_loss: 0.002179, f_loss: 0.059749
d pretrain epoch 28, step 0: dis_total_loss: 0.025794, r_loss: 0.001883, f_loss: 0.023911
d pretrain epoch 29, step 0: dis_total_loss: 0.028427, r_loss: 0.001638, f_loss: 0.026789
d pretrain epoch 30, step 0: dis_total_loss: 0.027611, r_loss: 0.001435, f_loss: 0.026176
d pretrain epoch 31, step 0: dis_total_loss: 0.028819, r_loss: 0.001255, f_loss: 0.027563
d pretrain epoch 32, step 0: dis_total_loss: 0.021687, r_loss: 0.001104, f_loss: 0.020582
d pretrain epoch 33, step 0: dis_total_loss: 0.024882, r_loss: 0.000973, f_loss: 0.023909
d pretrain epoch 34, step 0: dis_total_loss: 0.040071, r_loss: 0.000864, f_loss: 0.039207
d pretrain epoch 35, step 0: dis_total_loss: 0.015052, r_loss: 0.000766, f_loss: 0.014286
d pretrain epoch 36, step 0: dis_total_loss: 0.029080, r_loss: 0.000687, f_loss: 0.028393
d pretrain epoch 37, step 0: dis_total_loss: 0.012760, r_loss: 0.000613, f_loss: 0.012147
d pretrain epoch 38, step 0: dis_total_loss: 0.023577, r_loss: 0.000544, f_loss: 0.023033
d pretrain epoch 39, step 0: dis_total_loss: 0.011619, r_loss: 0.000487, f_loss: 0.011132
d pretrain epoch 40, step 0: dis_total_loss: 0.016789, r_loss: 0.000435, f_loss: 0.016353
d pretrain epoch 41, step 0: dis_total_loss: 0.016142, r_loss: 0.000392, f_loss: 0.015751
d pretrain epoch 42, step 0: dis_total_loss: 0.012217, r_loss: 0.000351, f_loss: 0.011866
d pretrain epoch 43, step 0: dis_total_loss: 0.007215, r_loss: 0.000315, f_loss: 0.006899
d pretrain epoch 44, step 0: dis_total_loss: 0.005775, r_loss: 0.000283, f_loss: 0.005492
d pretrain epoch 45, step 0: dis_total_loss: 0.009823, r_loss: 0.000255, f_loss: 0.009568
d pretrain epoch 46, step 0: dis_total_loss: 0.005619, r_loss: 0.000228, f_loss: 0.005390
d pretrain epoch 47, step 0: dis_total_loss: 0.007623, r_loss: 0.000206, f_loss: 0.007417
d pretrain epoch 48, step 0: dis_total_loss: 0.012784, r_loss: 0.000187, f_loss: 0.012597
d pretrain epoch 49, step 0: dis_total_loss: 0.005625, r_loss: 0.000169, f_loss: 0.005456
d pretrain epoch 50, step 0: dis_total_loss: 0.002912, r_loss: 0.000154, f_loss: 0.002758
d pretrain epoch 51, step 0: dis_total_loss: 0.000730, r_loss: 0.000140, f_loss: 0.000590
d pretrain epoch 52, step 0: dis_total_loss: 0.009749, r_loss: 0.000143, f_loss: 0.009606
d pretrain epoch 53, step 0: dis_total_loss: 0.005123, r_loss: 0.000128, f_loss: 0.004995
d pretrain epoch 54, step 0: dis_total_loss: 0.001912, r_loss: 0.000115, f_loss: 0.001798
d pretrain epoch 55, step 0: dis_total_loss: 0.008159, r_loss: 0.000104, f_loss: 0.008055
d pretrain epoch 56, step 0: dis_total_loss: 0.002609, r_loss: 0.000093, f_loss: 0.002516
d pretrain epoch 57, step 0: dis_total_loss: 0.001421, r_loss: 0.000083, f_loss: 0.001338
d pretrain epoch 58, step 0: dis_total_loss: 0.004324, r_loss: 0.000074, f_loss: 0.004250
d pretrain epoch 59, step 0: dis_total_loss: 0.002580, r_loss: 0.000066, f_loss: 0.002514
d pretrain epoch 60, step 0: dis_total_loss: 0.001769, r_loss: 0.000060, f_loss: 0.001709
d pretrain epoch 61, step 0: dis_total_loss: 0.003439, r_loss: 0.000054, f_loss: 0.003385
d pretrain epoch 62, step 0: dis_total_loss: 0.002217, r_loss: 0.000048, f_loss: 0.002168
d pretrain epoch 63, step 0: dis_total_loss: 0.004902, r_loss: 0.000044, f_loss: 0.004858
d pretrain epoch 64, step 0: dis_total_loss: 0.001859, r_loss: 0.000040, f_loss: 0.001820
d pretrain epoch 65, step 0: dis_total_loss: 0.005464, r_loss: 0.000035, f_loss: 0.005429
d pretrain epoch 66, step 0: dis_total_loss: 0.002309, r_loss: 0.000032, f_loss: 0.002277
d pretrain epoch 67, step 0: dis_total_loss: 0.000584, r_loss: 0.000029, f_loss: 0.000556
d pretrain epoch 68, step 0: dis_total_loss: 0.006788, r_loss: 0.000026, f_loss: 0.006762
d pretrain epoch 69, step 0: dis_total_loss: 0.000472, r_loss: 0.000023, f_loss: 0.000448
d pretrain epoch 70, step 0: dis_total_loss: 0.000206, r_loss: 0.000021, f_loss: 0.000184
d pretrain epoch 71, step 0: dis_total_loss: 0.002011, r_loss: 0.000019, f_loss: 0.001991
d pretrain epoch 72, step 0: dis_total_loss: 0.000132, r_loss: 0.000017, f_loss: 0.000115
d pretrain epoch 73, step 0: dis_total_loss: 0.000288, r_loss: 0.000016, f_loss: 0.000272
d pretrain epoch 74, step 0: dis_total_loss: 0.001062, r_loss: 0.000014, f_loss: 0.001048
d pretrain epoch 75, step 0: dis_total_loss: 0.004751, r_loss: 0.000013, f_loss: 0.004738
d pretrain epoch 76, step 0: dis_total_loss: 0.000369, r_loss: 0.000012, f_loss: 0.000358
d pretrain epoch 77, step 0: dis_total_loss: 0.001130, r_loss: 0.000011, f_loss: 0.001119
d pretrain epoch 78, step 0: dis_total_loss: 0.000319, r_loss: 0.000009, f_loss: 0.000310
d pretrain epoch 79, step 0: dis_total_loss: 0.000097, r_loss: 0.000009, f_loss: 0.000088
epoch  80, step: 1: mean_reward: -56.315876, expect_reward_loss:-56.315876, update_loss: 9194.217773
d update  epoch 80, step 0: dis_total_loss: 0.000091, r_loss: 0.000008, f_loss: 0.000083
epoch 80 BLEU1~4 on train dataset:
0.827134
0.584003
0.318836
0.140222

 epoch 80 BLEU1~4 on test dataset:
0.609596
0.304801
0.125057
0.044036


epoch  81, step: 1: mean_reward: -56.507019, expect_reward_loss:-56.507019, update_loss: 10523.346680
d update  epoch 81, step 0: dis_total_loss: 0.000230, r_loss: 0.000008, f_loss: 0.000222
epoch  82, step: 1: mean_reward: -55.789913, expect_reward_loss:-55.789913, update_loss: 11989.979492
d update  epoch 82, step 0: dis_total_loss: 0.001410, r_loss: 0.000008, f_loss: 0.001402
epoch  83, step: 1: mean_reward: -56.127701, expect_reward_loss:-56.127701, update_loss: 11736.824219
d update  epoch 83, step 0: dis_total_loss: 0.000133, r_loss: 0.000007, f_loss: 0.000126
epoch  84, step: 1: mean_reward: -56.720543, expect_reward_loss:-56.720543, update_loss: 10838.058594
d update  epoch 84, step 0: dis_total_loss: 0.000047, r_loss: 0.000007, f_loss: 0.000039
epoch  85, step: 1: mean_reward: -56.338570, expect_reward_loss:-56.338570, update_loss: 10924.535156
d update  epoch 85, step 0: dis_total_loss: 0.000803, r_loss: 0.000007, f_loss: 0.000796
epoch  86, step: 1: mean_reward: -56.030750, expect_reward_loss:-56.030750, update_loss: 11801.970703
d update  epoch 86, step 0: dis_total_loss: 0.000203, r_loss: 0.000007, f_loss: 0.000196
epoch  87, step: 1: mean_reward: -56.537361, expect_reward_loss:-56.537361, update_loss: 10267.051758
d update  epoch 87, step 0: dis_total_loss: 0.002063, r_loss: 0.000007, f_loss: 0.002056
epoch  88, step: 1: mean_reward: -56.207134, expect_reward_loss:-56.207134, update_loss: 12101.996094
d update  epoch 88, step 0: dis_total_loss: 0.000861, r_loss: 0.000007, f_loss: 0.000854
epoch  89, step: 1: mean_reward: -56.769154, expect_reward_loss:-56.769154, update_loss: 10926.596680
d update  epoch 89, step 0: dis_total_loss: 0.000213, r_loss: 0.000007, f_loss: 0.000206
epoch  90, step: 1: mean_reward: -56.870354, expect_reward_loss:-56.870354, update_loss: 10936.053711
d update  epoch 90, step 0: dis_total_loss: 0.000785, r_loss: 0.000007, f_loss: 0.000778
epoch 90 BLEU1~4 on train dataset:
0.816109
0.577629
0.316310
0.139386

 epoch 90 BLEU1~4 on test dataset:
0.598139
0.298845
0.121124
0.042348


epoch  91, step: 1: mean_reward: -56.793282, expect_reward_loss:-56.793282, update_loss: 10641.099609
d update  epoch 91, step 0: dis_total_loss: 0.001967, r_loss: 0.000007, f_loss: 0.001960
epoch  92, step: 1: mean_reward: -56.769485, expect_reward_loss:-56.769485, update_loss: 11085.613281
d update  epoch 92, step 0: dis_total_loss: 0.000478, r_loss: 0.000007, f_loss: 0.000471
epoch  93, step: 1: mean_reward: -56.657364, expect_reward_loss:-56.657364, update_loss: 12248.925781
d update  epoch 93, step 0: dis_total_loss: 0.000191, r_loss: 0.000007, f_loss: 0.000185
epoch  94, step: 1: mean_reward: -56.799835, expect_reward_loss:-56.799835, update_loss: 10761.939453
d update  epoch 94, step 0: dis_total_loss: 0.000096, r_loss: 0.000007, f_loss: 0.000089
epoch  95, step: 1: mean_reward: -57.119171, expect_reward_loss:-57.119171, update_loss: 12800.820312
d update  epoch 95, step 0: dis_total_loss: 0.000115, r_loss: 0.000007, f_loss: 0.000109
epoch  96, step: 1: mean_reward: -57.098381, expect_reward_loss:-57.098381, update_loss: 10316.310547
d update  epoch 96, step 0: dis_total_loss: 0.000143, r_loss: 0.000006, f_loss: 0.000137
epoch  97, step: 1: mean_reward: -57.060280, expect_reward_loss:-57.060280, update_loss: 10918.619141
d update  epoch 97, step 0: dis_total_loss: 0.000283, r_loss: 0.000006, f_loss: 0.000277
epoch  98, step: 1: mean_reward: -56.615952, expect_reward_loss:-56.615952, update_loss: 11845.172852
d update  epoch 98, step 0: dis_total_loss: 0.001262, r_loss: 0.000006, f_loss: 0.001255
epoch  99, step: 1: mean_reward: -57.184334, expect_reward_loss:-57.184334, update_loss: 10643.412109
d update  epoch 99, step 0: dis_total_loss: 0.000294, r_loss: 0.000006, f_loss: 0.000288
epoch 100, step: 1: mean_reward: -56.976364, expect_reward_loss:-56.976364, update_loss: 11051.541016
d update  epoch 100, step 0: dis_total_loss: 0.000477, r_loss: 0.000006, f_loss: 0.000471
epoch 100 BLEU1~4 on train dataset:
0.810316
0.573385
0.314704
0.137541

 epoch 100 BLEU1~4 on test dataset:
0.597748
0.299427
0.121110
0.041880


epoch 101, step: 1: mean_reward: -56.910233, expect_reward_loss:-56.910233, update_loss: 11236.255859
d update  epoch 101, step 0: dis_total_loss: 0.000782, r_loss: 0.000006, f_loss: 0.000776
epoch 102, step: 1: mean_reward: -57.143303, expect_reward_loss:-57.143303, update_loss: 11573.258789
d update  epoch 102, step 0: dis_total_loss: 0.000017, r_loss: 0.000006, f_loss: 0.000011
epoch 103, step: 1: mean_reward: -57.289261, expect_reward_loss:-57.289261, update_loss: 12605.013672
d update  epoch 103, step 0: dis_total_loss: 0.000235, r_loss: 0.000006, f_loss: 0.000229
epoch 104, step: 1: mean_reward: -57.359711, expect_reward_loss:-57.359711, update_loss: 12102.895508
d update  epoch 104, step 0: dis_total_loss: 0.000539, r_loss: 0.000006, f_loss: 0.000533
epoch 105, step: 1: mean_reward: -57.134079, expect_reward_loss:-57.134079, update_loss: 11468.052734
d update  epoch 105, step 0: dis_total_loss: 0.000030, r_loss: 0.000006, f_loss: 0.000024
epoch 106, step: 1: mean_reward: -57.477226, expect_reward_loss:-57.477226, update_loss: 10822.287109
d update  epoch 106, step 0: dis_total_loss: 0.000237, r_loss: 0.000006, f_loss: 0.000231
epoch 107, step: 1: mean_reward: -57.387115, expect_reward_loss:-57.387115, update_loss: 11006.791992
d update  epoch 107, step 0: dis_total_loss: 0.000334, r_loss: 0.000006, f_loss: 0.000329
epoch 108, step: 1: mean_reward: -57.360451, expect_reward_loss:-57.360451, update_loss: 11364.768555
d update  epoch 108, step 0: dis_total_loss: 0.000140, r_loss: 0.000006, f_loss: 0.000135
epoch 109, step: 1: mean_reward: -57.568001, expect_reward_loss:-57.568001, update_loss: 12591.934570
d update  epoch 109, step 0: dis_total_loss: 0.001836, r_loss: 0.000006, f_loss: 0.001830
epoch 110, step: 1: mean_reward: -57.550152, expect_reward_loss:-57.550152, update_loss: 11914.633789
d update  epoch 110, step 0: dis_total_loss: 0.000056, r_loss: 0.000006, f_loss: 0.000051
epoch 110 BLEU1~4 on train dataset:
0.800724
0.571603
0.313827
0.139560

 epoch 110 BLEU1~4 on test dataset:
0.592645
0.296930
0.121653
0.042565


epoch 111, step: 1: mean_reward: -57.406174, expect_reward_loss:-57.406174, update_loss: 12924.776367
d update  epoch 111, step 0: dis_total_loss: 0.000063, r_loss: 0.000006, f_loss: 0.000058
epoch 112, step: 1: mean_reward: -57.221596, expect_reward_loss:-57.221596, update_loss: 12596.265625
d update  epoch 112, step 0: dis_total_loss: 0.000235, r_loss: 0.000005, f_loss: 0.000229
epoch 113, step: 1: mean_reward: -57.797657, expect_reward_loss:-57.797657, update_loss: 11102.172852
d update  epoch 113, step 0: dis_total_loss: 0.000183, r_loss: 0.000005, f_loss: 0.000178
epoch 114, step: 1: mean_reward: -57.698872, expect_reward_loss:-57.698872, update_loss: 11591.025391
d update  epoch 114, step 0: dis_total_loss: 0.000140, r_loss: 0.000005, f_loss: 0.000135
epoch 115, step: 1: mean_reward: -57.721901, expect_reward_loss:-57.721901, update_loss: 10380.060547
d update  epoch 115, step 0: dis_total_loss: 0.000129, r_loss: 0.000005, f_loss: 0.000124
epoch 116, step: 1: mean_reward: -57.514431, expect_reward_loss:-57.514431, update_loss: 11966.837891
d update  epoch 116, step 0: dis_total_loss: 0.000060, r_loss: 0.000005, f_loss: 0.000055
epoch 117, step: 1: mean_reward: -57.724373, expect_reward_loss:-57.724373, update_loss: 10673.689453
d update  epoch 117, step 0: dis_total_loss: 0.000115, r_loss: 0.000005, f_loss: 0.000110
epoch 118, step: 1: mean_reward: -57.858681, expect_reward_loss:-57.858681, update_loss: 12318.625977
d update  epoch 118, step 0: dis_total_loss: 0.000022, r_loss: 0.000005, f_loss: 0.000017
epoch 119, step: 1: mean_reward: -57.805286, expect_reward_loss:-57.805286, update_loss: 10976.551758
d update  epoch 119, step 0: dis_total_loss: 0.000010, r_loss: 0.000005, f_loss: 0.000005
epoch 120, step: 1: mean_reward: -57.590763, expect_reward_loss:-57.590763, update_loss: 12326.754883
d update  epoch 120, step 0: dis_total_loss: 0.000144, r_loss: 0.000005, f_loss: 0.000139
epoch 120 BLEU1~4 on train dataset:
0.790480
0.563744
0.310140
0.136288

 epoch 120 BLEU1~4 on test dataset:
0.589251
0.294739
0.121343
0.042387


epoch 121, step: 1: mean_reward: -58.172493, expect_reward_loss:-58.172493, update_loss: 10857.109375
d update  epoch 121, step 0: dis_total_loss: 0.000220, r_loss: 0.000005, f_loss: 0.000215
epoch 122, step: 1: mean_reward: -58.050007, expect_reward_loss:-58.050007, update_loss: 12144.283203
d update  epoch 122, step 0: dis_total_loss: 0.000019, r_loss: 0.000005, f_loss: 0.000014
epoch 123, step: 1: mean_reward: -57.483154, expect_reward_loss:-57.483154, update_loss: 11600.051758
d update  epoch 123, step 0: dis_total_loss: 0.000178, r_loss: 0.000005, f_loss: 0.000173
epoch 124, step: 1: mean_reward: -58.008583, expect_reward_loss:-58.008583, update_loss: 11641.038086
d update  epoch 124, step 0: dis_total_loss: 0.000614, r_loss: 0.000005, f_loss: 0.000609
epoch 125, step: 1: mean_reward: -58.174751, expect_reward_loss:-58.174751, update_loss: 12018.200195
d update  epoch 125, step 0: dis_total_loss: 0.000074, r_loss: 0.000005, f_loss: 0.000070
epoch 126, step: 1: mean_reward: -58.244286, expect_reward_loss:-58.244286, update_loss: 12962.243164
d update  epoch 126, step 0: dis_total_loss: 0.000159, r_loss: 0.000005, f_loss: 0.000154
epoch 127, step: 1: mean_reward: -58.012901, expect_reward_loss:-58.012901, update_loss: 11138.433594
d update  epoch 127, step 0: dis_total_loss: 0.000260, r_loss: 0.000005, f_loss: 0.000256
epoch 128, step: 1: mean_reward: -58.294884, expect_reward_loss:-58.294884, update_loss: 12905.900391
d update  epoch 128, step 0: dis_total_loss: 0.003023, r_loss: 0.000005, f_loss: 0.003019
epoch 129, step: 1: mean_reward: -58.201733, expect_reward_loss:-58.201733, update_loss: 12453.796875
d update  epoch 129, step 0: dis_total_loss: 0.000177, r_loss: 0.000005, f_loss: 0.000172
epoch 130, step: 1: mean_reward: -58.158852, expect_reward_loss:-58.158852, update_loss: 11840.204102
d update  epoch 130, step 0: dis_total_loss: 0.000058, r_loss: 0.000005, f_loss: 0.000053
epoch 130 BLEU1~4 on train dataset:
0.783577
0.562079
0.309143
0.134705

 epoch 130 BLEU1~4 on test dataset:
0.583893
0.293252
0.118825
0.041849


epoch 131, step: 1: mean_reward: -58.214989, expect_reward_loss:-58.214989, update_loss: 11653.859375
d update  epoch 131, step 0: dis_total_loss: 0.000719, r_loss: 0.000005, f_loss: 0.000714
epoch 132, step: 1: mean_reward: -58.335285, expect_reward_loss:-58.335285, update_loss: 12571.239258
d update  epoch 132, step 0: dis_total_loss: 0.000065, r_loss: 0.000005, f_loss: 0.000061
epoch 133, step: 1: mean_reward: -57.909302, expect_reward_loss:-57.909302, update_loss: 13907.671875
d update  epoch 133, step 0: dis_total_loss: 0.000019, r_loss: 0.000004, f_loss: 0.000014
epoch 134, step: 1: mean_reward: -58.363594, expect_reward_loss:-58.363594, update_loss: 12145.355469
d update  epoch 134, step 0: dis_total_loss: 0.000528, r_loss: 0.000004, f_loss: 0.000524
epoch 135, step: 1: mean_reward: -58.354298, expect_reward_loss:-58.354298, update_loss: 12430.209961
d update  epoch 135, step 0: dis_total_loss: 0.000033, r_loss: 0.000004, f_loss: 0.000028
epoch 136, step: 1: mean_reward: -58.408398, expect_reward_loss:-58.408398, update_loss: 12149.582031
d update  epoch 136, step 0: dis_total_loss: 0.000123, r_loss: 0.000004, f_loss: 0.000119
epoch 137, step: 1: mean_reward: -58.329945, expect_reward_loss:-58.329945, update_loss: 12714.979492
d update  epoch 137, step 0: dis_total_loss: 0.000654, r_loss: 0.000004, f_loss: 0.000649
epoch 138, step: 1: mean_reward: -58.375885, expect_reward_loss:-58.375885, update_loss: 13204.132812
d update  epoch 138, step 0: dis_total_loss: 0.000525, r_loss: 0.000004, f_loss: 0.000521
epoch 139, step: 1: mean_reward: -58.199024, expect_reward_loss:-58.199024, update_loss: 11656.193359
d update  epoch 139, step 0: dis_total_loss: 0.000045, r_loss: 0.000004, f_loss: 0.000041
epoch 140, step: 1: mean_reward: -58.300331, expect_reward_loss:-58.300331, update_loss: 12846.854492
d update  epoch 140, step 0: dis_total_loss: 0.000109, r_loss: 0.000004, f_loss: 0.000104
epoch 140 BLEU1~4 on train dataset:
0.773427
0.556043
0.307813
0.135709

 epoch 140 BLEU1~4 on test dataset:
0.578120
0.290229
0.118377
0.041081


epoch 141, step: 1: mean_reward: -58.488934, expect_reward_loss:-58.488934, update_loss: 12392.701172
d update  epoch 141, step 0: dis_total_loss: 0.000043, r_loss: 0.000004, f_loss: 0.000039
epoch 142, step: 1: mean_reward: -58.158978, expect_reward_loss:-58.158978, update_loss: 13064.098633
d update  epoch 142, step 0: dis_total_loss: 0.000015, r_loss: 0.000004, f_loss: 0.000011
epoch 143, step: 1: mean_reward: -58.408947, expect_reward_loss:-58.408947, update_loss: 12768.065430/home/syp/miniconda2/envs/newtf/lib/python3.6/importlib/_bootstrap.py:205: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6
  return f(*args, **kwds)

d update  epoch 143, step 0: dis_total_loss: 0.000328, r_loss: 0.000004, f_loss: 0.000324
epoch 144, step: 1: mean_reward: -58.335255, expect_reward_loss:-58.335255, update_loss: 12738.136719
d update  epoch 144, step 0: dis_total_loss: 0.000022, r_loss: 0.000004, f_loss: 0.000017
epoch 145, step: 1: mean_reward: -58.559151, expect_reward_loss:-58.559151, update_loss: 13076.791016
d update  epoch 145, step 0: dis_total_loss: 0.000086, r_loss: 0.000004, f_loss: 0.000082
epoch 146, step: 1: mean_reward: -58.320202, expect_reward_loss:-58.320202, update_loss: 13058.248047
d update  epoch 146, step 0: dis_total_loss: 0.002201, r_loss: 0.000004, f_loss: 0.002197
epoch 147, step: 1: mean_reward: -58.628162, expect_reward_loss:-58.628162, update_loss: 13288.483398
d update  epoch 147, step 0: dis_total_loss: 0.000045, r_loss: 0.000004, f_loss: 0.000041
epoch 148, step: 1: mean_reward: -58.517677, expect_reward_loss:-58.517677, update_loss: 12464.628906
d update  epoch 148, step 0: dis_total_loss: 0.000468, r_loss: 0.000004, f_loss: 0.000464
epoch 149, step: 1: mean_reward: -58.657642, expect_reward_loss:-58.657642, update_loss: 12658.649414
d update  epoch 149, step 0: dis_total_loss: 0.000335, r_loss: 0.000004, f_loss: 0.000331
epoch 150, step: 1: mean_reward: -58.668129, expect_reward_loss:-58.668129, update_loss: 13928.205078
d update  epoch 150, step 0: dis_total_loss: 0.000057, r_loss: 0.000004, f_loss: 0.000054
epoch 150 BLEU1~4 on train dataset:
0.758644
0.548486
0.306279
0.136093

 epoch 150 BLEU1~4 on test dataset:
0.568462
0.288588
0.118463
0.042214


epoch 151, step: 1: mean_reward: -58.344154, expect_reward_loss:-58.344154, update_loss: 12886.481445
d update  epoch 151, step 0: dis_total_loss: 0.000039, r_loss: 0.000004, f_loss: 0.000035
epoch 152, step: 1: mean_reward: -58.372997, expect_reward_loss:-58.372997, update_loss: 14175.951172
d update  epoch 152, step 0: dis_total_loss: 0.000226, r_loss: 0.000004, f_loss: 0.000222
epoch 153, step: 1: mean_reward: -58.592846, expect_reward_loss:-58.592846, update_loss: 14692.143555
d update  epoch 153, step 0: dis_total_loss: 0.000627, r_loss: 0.000004, f_loss: 0.000623
epoch 154, step: 1: mean_reward: -58.548058, expect_reward_loss:-58.548058, update_loss: 12365.054688
d update  epoch 154, step 0: dis_total_loss: 0.000023, r_loss: 0.000004, f_loss: 0.000020
epoch 155, step: 1: mean_reward: -58.515423, expect_reward_loss:-58.515423, update_loss: 13680.370117
d update  epoch 155, step 0: dis_total_loss: 0.000103, r_loss: 0.000004, f_loss: 0.000100
epoch 156, step: 1: mean_reward: -58.579590, expect_reward_loss:-58.579590, update_loss: 13951.057617
d update  epoch 156, step 0: dis_total_loss: 0.000190, r_loss: 0.000004, f_loss: 0.000187
epoch 157, step: 1: mean_reward: -58.722340, expect_reward_loss:-58.722340, update_loss: 14695.876953
d update  epoch 157, step 0: dis_total_loss: 0.000021, r_loss: 0.000004, f_loss: 0.000017
epoch 158, step: 1: mean_reward: -58.477684, expect_reward_loss:-58.477684, update_loss: 12929.532227
d update  epoch 158, step 0: dis_total_loss: 0.000614, r_loss: 0.000004, f_loss: 0.000611
epoch 159, step: 1: mean_reward: -58.547413, expect_reward_loss:-58.547413, update_loss: 13668.491211
d update  epoch 159, step 0: dis_total_loss: 0.000267, r_loss: 0.000003, f_loss: 0.000263
epoch 160, step: 1: mean_reward: -58.436714, expect_reward_loss:-58.436714, update_loss: 12541.197266
d update  epoch 160, step 0: dis_total_loss: 0.000065, r_loss: 0.000003, f_loss: 0.000062
epoch 160 BLEU1~4 on train dataset:
0.743869
0.540951
0.303380
0.135030

 epoch 160 BLEU1~4 on test dataset:
0.561121
0.286729
0.118643
0.041264


epoch 161, step: 1: mean_reward: -58.509686, expect_reward_loss:-58.509686, update_loss: 13048.333984
d update  epoch 161, step 0: dis_total_loss: 0.000345, r_loss: 0.000003, f_loss: 0.000342
epoch 162, step: 1: mean_reward: -58.593861, expect_reward_loss:-58.593861, update_loss: 15426.025391
d update  epoch 162, step 0: dis_total_loss: 0.000084, r_loss: 0.000003, f_loss: 0.000081
epoch 163, step: 1: mean_reward: -58.555500, expect_reward_loss:-58.555500, update_loss: 13722.518555
d update  epoch 163, step 0: dis_total_loss: 0.000167, r_loss: 0.000003, f_loss: 0.000163
epoch 164, step: 1: mean_reward: -58.437145, expect_reward_loss:-58.437145, update_loss: 14253.749023
d update  epoch 164, step 0: dis_total_loss: 0.000130, r_loss: 0.000003, f_loss: 0.000126
epoch 165, step: 1: mean_reward: -58.413807, expect_reward_loss:-58.413807, update_loss: 14134.447266
d update  epoch 165, step 0: dis_total_loss: 0.000461, r_loss: 0.000003, f_loss: 0.000458
epoch 166, step: 1: mean_reward: -58.469910, expect_reward_loss:-58.469910, update_loss: 15174.287109
d update  epoch 166, step 0: dis_total_loss: 0.000143, r_loss: 0.000003, f_loss: 0.000139
epoch 167, step: 1: mean_reward: -58.514019, expect_reward_loss:-58.514019, update_loss: 14760.121094
d update  epoch 167, step 0: dis_total_loss: 0.000131, r_loss: 0.000003, f_loss: 0.000128
epoch 168, step: 1: mean_reward: -58.437202, expect_reward_loss:-58.437202, update_loss: 14050.265625
d update  epoch 168, step 0: dis_total_loss: 0.000049, r_loss: 0.000003, f_loss: 0.000046
epoch 169, step: 1: mean_reward: -58.529560, expect_reward_loss:-58.529560, update_loss: 15682.392578
d update  epoch 169, step 0: dis_total_loss: 0.000016, r_loss: 0.000003, f_loss: 0.000013
epoch 170, step: 1: mean_reward: -58.196552, expect_reward_loss:-58.196552, update_loss: 13001.189453
d update  epoch 170, step 0: dis_total_loss: 0.000167, r_loss: 0.000003, f_loss: 0.000164
epoch 170 BLEU1~4 on train dataset:
0.726647
0.530675
0.299362
0.133602

 epoch 170 BLEU1~4 on test dataset:
0.548151
0.283765
0.118528
0.042177


epoch 171, step: 1: mean_reward: -58.227497, expect_reward_loss:-58.227497, update_loss: 13133.020508
d update  epoch 171, step 0: dis_total_loss: 0.000048, r_loss: 0.000003, f_loss: 0.000045
epoch 172, step: 1: mean_reward: -58.252647, expect_reward_loss:-58.252647, update_loss: 14499.826172
d update  epoch 172, step 0: dis_total_loss: 0.000010, r_loss: 0.000003, f_loss: 0.000007
epoch 173, step: 1: mean_reward: -58.322357, expect_reward_loss:-58.322357, update_loss: 12713.644531
d update  epoch 173, step 0: dis_total_loss: 0.000189, r_loss: 0.000003, f_loss: 0.000186
epoch 174, step: 1: mean_reward: -58.075001, expect_reward_loss:-58.075001, update_loss: 13676.058594
d update  epoch 174, step 0: dis_total_loss: 0.000087, r_loss: 0.000003, f_loss: 0.000084
epoch 175, step: 1: mean_reward: -58.121315, expect_reward_loss:-58.121315, update_loss: 14767.250977
d update  epoch 175, step 0: dis_total_loss: 0.001592, r_loss: 0.000003, f_loss: 0.001589
epoch 176, step: 1: mean_reward: -58.330608, expect_reward_loss:-58.330608, update_loss: 12503.548828
d update  epoch 176, step 0: dis_total_loss: 0.000188, r_loss: 0.000003, f_loss: 0.000185
epoch 177, step: 1: mean_reward: -58.115253, expect_reward_loss:-58.115253, update_loss: 14490.913086
d update  epoch 177, step 0: dis_total_loss: 0.000380, r_loss: 0.000003, f_loss: 0.000377
epoch 178, step: 1: mean_reward: -58.171032, expect_reward_loss:-58.171032, update_loss: 15077.129883
d update  epoch 178, step 0: dis_total_loss: 0.000073, r_loss: 0.000003, f_loss: 0.000070
epoch 179, step: 1: mean_reward: -58.190083, expect_reward_loss:-58.190083, update_loss: 14430.581055
d update  epoch 179, step 0: dis_total_loss: 0.000019, r_loss: 0.000003, f_loss: 0.000016
epoch 179 BLEU1~4 on train dataset:
0.714270
0.523022
0.296147
0.133592

 epoch 179 BLEU1~4 on test dataset:
0.540159
0.278988
0.116260
0.041746


